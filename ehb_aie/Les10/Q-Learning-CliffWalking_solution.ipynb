{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_X39pQ5tVP4"
   },
   "source": [
    "# Train an agent to play Cliff Walking using Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss-eZTqjte3O"
   },
   "source": [
    "[Gym](https://gym.openai.com/) is a toolkit for developing and comparing reinforcement algorithms. It contains several test problem (*environments*) that have a shared interface, allowing you to write general algorithms. \n",
    "\n",
    "Let's start with importing all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "K5LVzQUirmiF"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in /opt/anaconda3/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (4.11.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (2.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install 'gymnasium[classic-control]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfP0PR7_tlLY"
   },
   "source": [
    "## Description of the game\n",
    "\n",
    "The Cliff Walking environment in Gymnasium (previously part of OpenAI Gym) is like this:\n",
    "\n",
    "Imagine a grid ‚Äî like a checkerboard ‚Äî where you start in the bottom-left corner.\n",
    "Your goal is to reach the bottom-right corner.\n",
    "But! Between you and the goal, along the bottom row, is a cliff ‚Äî a dangerous area.\n",
    "If you step into the cliff, you \"fall off,\" get a big negative reward (penalty), and you‚Äôre sent back to the start.\n",
    "If you manage to walk safely around the cliff and reach the goal, you win.\n",
    "More details:\n",
    "\n",
    "Each move (up, down, left, right) gives a small penalty (like -1 reward) because they want to encourage you to find the fastest route.\n",
    "Falling off the cliff gives a huge penalty (like -100).\n",
    "The \"safe\" path is usually to move right across the second-to-last row, and only at the end move down carefully to the goal.\n",
    "\n",
    "More info on: https://gymnasium.farama.org/environments/toy_text/cliff_walking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "V90ySjfLtynA"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgsfBm4At2Lg"
   },
   "source": [
    "## Initialize the Q-table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6lM_cuat-9q"
   },
   "source": [
    "Remember: \n",
    "- number of rows: number of states\n",
    "- number of columns: number of actions\n",
    "q-table: np array of dimension (states, actions)\n",
    "\n",
    "add some things on how to make np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "WcMatYVCuXM1"
   },
   "outputs": [],
   "source": [
    "state_space_size = env.observation_space.n\n",
    "action_space_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "O7Rr1yo1ujag"
   },
   "outputs": [],
   "source": [
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1618321123871,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "dbuj_-HCunZu",
    "outputId": "e1360b6e-180b-47c1-e7a9-47abe8530f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iZkcf_1vL3Y"
   },
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot-2RUGvOl9"
   },
   "source": [
    "In this section we will initialize the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Booh7w41vfLw"
   },
   "source": [
    "The first one is the *discount factor*. This is a number in [0,1] indicating how much the agent cares about rewards in the future relative to those in the immediate future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "liMcepGyw3uW"
   },
   "outputs": [],
   "source": [
    "discount_factor = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CthvEAPRy0bg"
   },
   "source": [
    "The second parameter is the *learning rate*. This is a number in [0,1] indicating how quickly the agent will adopt the new (learned) Q-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "GiAiP3b0zRnr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATMjtQ1wzZT-"
   },
   "source": [
    "Finally we set the necessary parameters to deal with the trade-off between exploration and exploitation. We have to set\n",
    "- *initial exploration rate*: upper bound for the exploration rate and initial exploration rate, we will use this to update the exploration rate\n",
    "- *minimum exploration rate*: lower bound for the exploration rate, by setting it to a value greater than 0, we make sure there is always a probability for exploration\n",
    "- *exploration rate*: probability that the agent will explore, will be updated after each episode, using exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity, $N(t)$ is the quantity at time step $t$ and $\\lambda$ is the rate of decay.\n",
    "- *exploration rate decay*: how fast or slow does the exploration rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "I9qm0lw2-sn9"
   },
   "outputs": [],
   "source": [
    "initial_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_rate = 1\n",
    "exploration_decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eYlK0-c-45x"
   },
   "source": [
    "We also set number of episodes and maximum number of steps per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "DFurhi73_AsW"
   },
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "max_steps_per_episode = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaA0V6O9_TzJ"
   },
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SrazgwEAaN5"
   },
   "source": [
    "Store the total rewards for each episode. This is for diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mmxraf1dekU"
   },
   "source": [
    "If an episode is succesfull this translate to reward 1 if not to reward 0, so we can use this array to check % of successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "XuCPM2laARJs"
   },
   "outputs": [],
   "source": [
    "rewards = np.zeros(num_episodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0yUfNqCHP8"
   },
   "source": [
    "In each episode:\n",
    "1.   Reset environment\n",
    "2.   For each step in the episode:\n",
    "  - pick an action $a$ by generating a random float $r$ in $[0,1]$\n",
    "    - if $r > \\epsilon$ we choose the next action by exploitation\n",
    "    - if $r \\leq \\epsilon$ we choose the next action by exploration\n",
    "  - take action $a$ and observe reward $R$ and next state $s'$\n",
    "  - update Q-table \n",
    "  $$ q(s,a) = q(s,a) + \\alpha(R + \\gamma max_{a'} q(s', a') - q(s,a)) $$\n",
    "3. decrease exploration rate proportional to its current value, we will use exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity and $N(t)$ is the quantity at time step $t$.\n",
    "\n",
    "\n",
    "\n",
    "with \n",
    "- $\\epsilon$ the exploration rate,\n",
    "- $\\lambda$ the exploration rate decay,\n",
    "- $\\alpha$ the learning rate and \n",
    "- $\\gamma$ the discount factor.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "zOvIxI_A_V9J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0] # start with a clean slate\n",
    "    reward_episode = 0 # keep track of total reward for this episode\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        # exploration or exploitation? -> we need to pick a random float in 0 and 1\n",
    "        exploration_rate_treshold = random.uniform(0,1)\n",
    "        if exploration_rate_treshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state]) #exploitation: look in row \"state\" which column \"action\" has the highest value\n",
    "        else:\n",
    "            action = env.action_space.sample() #exploration: random action\n",
    "\n",
    "        # take a step in the environment: let's store the new state under a new name since we still need to use the old state\n",
    "        new_state, reward, terminated, truncated , info = env.step(action)\n",
    "        \n",
    "        # terminated = True if environment terminates (eg. due to task completion, failure etc.)\n",
    "        # truncated = True if episode truncates due to a time limit or a reason that is not defined as part of the task.\n",
    "        done = truncated or terminated \n",
    "\n",
    "        # update q-table for current (state, action) pair\n",
    "        q_table[state, action] += learning_rate *\\\n",
    "         (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
    "\n",
    "        # update state\n",
    "        state = new_state\n",
    "        # update reward episode\n",
    "        reward_episode += reward # rewards[episode] += reward\n",
    "\n",
    "        # check if episode ended\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # add reward current episode to rewards array\n",
    "    rewards[episode] = reward_episode\n",
    "\n",
    "    # update exploration rate\n",
    "    exploration_rate = max(initial_exploration_rate * np.exp(- exploration_decay_rate * episode), min_exploration_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsE0vf_ArDFX"
   },
   "source": [
    "Let's print the average reward per thousand episodes, this way we can get an idea about how rewards have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "KduAhbZ3ZuAI"
   },
   "outputs": [],
   "source": [
    "rewards_per_thousand_episodes = np.split(rewards, num_episodes/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after  1000  episodes:  -566.707\n",
      "after  2000  episodes:  -126.915\n",
      "after  3000  episodes:  -48.311\n",
      "after  4000  episodes:  -21.874\n",
      "after  5000  episodes:  -18.055\n",
      "after  6000  episodes:  -15.057\n",
      "after  7000  episodes:  -15.601\n",
      "after  8000  episodes:  -15.23\n",
      "after  9000  episodes:  -16.646\n",
      "after  10000  episodes:  -17.048\n"
     ]
    }
   ],
   "source": [
    "count = 1000\n",
    "for reward_group in rewards_per_thousand_episodes:\n",
    "    print(\"after \", count, \" episodes: \", np.average(reward_group))\n",
    "    count+=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvt3Zx5_O-X"
   },
   "source": [
    "Let's also visualize the *learning curve* by plotting the moving average using a window length of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "BnJK6G4Z-9Yg"
   },
   "outputs": [],
   "source": [
    "def moving_average(array, window):\n",
    "    return np.convolve(array, np.ones(window), 'valid') / window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1618321543335,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "C-npvt2E_HIY",
    "outputId": "669283d5-cee7-4a03-a96b-8d2cb7997085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-566.707, -565.836, -566.32 , ...,  -17.05 ,  -17.048,  -17.048])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_average(rewards, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1618321555999,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "ZYCLeHCm_YwY",
    "outputId": "01d176c1-b242-42f3-8a7b-3631c5a9442b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(999, 10000), moving_average(rewards, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3OyJMQ1ryRs"
   },
   "source": [
    "## Optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOCvgWWdqYyw"
   },
   "source": [
    "Let's print the q_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1618321716577,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "6pXJnq4KWDtR",
    "outputId": "c83ec5f1-1fc0-45e7-89e9-8d801049f427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -13.52621724,  -13.0732419 ,  -13.07531888,  -13.21962343],\n",
       "       [ -12.73354166,  -12.23922555,  -12.23980848,  -13.57077037],\n",
       "       [ -12.17075106,  -11.35978053,  -11.35976357,  -12.93305571],\n",
       "       [ -11.28961446,  -10.46552998,  -10.46555952,  -12.20210777],\n",
       "       [ -10.4461629 ,   -9.56152798,   -9.56151628,  -11.29721431],\n",
       "       [  -9.53529213,   -8.64815645,   -8.64816791,  -10.38447816],\n",
       "       [  -8.62149862,   -7.72545702,   -7.72546039,   -9.54695647],\n",
       "       [  -7.7022395 ,   -6.79343332,   -6.79343417,   -8.60677116],\n",
       "       [  -6.78311613,   -5.85197141,   -5.85197141,   -7.67629567],\n",
       "       [  -5.84014518,   -4.90099022,   -4.90099002,   -6.74300777],\n",
       "       [  -4.85475422,   -3.94039763,   -3.9403976 ,   -5.83337763],\n",
       "       [  -3.92602139,   -3.92225116,   -2.9701    ,   -4.84975266],\n",
       "       [ -13.89652881,  -12.2478977 ,  -12.2478977 ,  -13.12486435],\n",
       "       [ -13.10125095,  -11.36151283,  -11.36151283,  -13.12513059],\n",
       "       [ -12.24232855,  -10.46617457,  -10.46617457,  -12.24783181],\n",
       "       [ -11.35980304,   -9.5617925 ,   -9.5617925 ,  -11.36141746],\n",
       "       [ -10.46512073,   -8.64827525,   -8.64827525,  -10.46595443],\n",
       "       [  -9.56126861,   -7.72553056,   -7.72553056,   -9.5617304 ],\n",
       "       [  -8.64726165,   -6.79346521,   -6.79346521,   -8.64818711],\n",
       "       [  -7.72528844,   -5.85198506,   -5.85198506,   -7.7253925 ],\n",
       "       [  -6.79268645,   -4.90099501,   -4.90099501,   -6.79340934],\n",
       "       [  -5.85160932,   -3.940399  ,   -3.940399  ,   -5.85169012],\n",
       "       [  -4.90055869,   -2.9701    ,   -2.9701    ,   -4.90064202],\n",
       "       [  -3.9402164 ,   -2.96987398,   -1.99      ,   -3.93868237],\n",
       "       [ -13.12541872,  -11.36151283,  -13.12541872,  -12.2478977 ],\n",
       "       [ -12.2478977 ,  -10.46617457, -112.12541872,  -12.2478977 ],\n",
       "       [ -11.36151283,   -9.5617925 , -112.12541872,  -11.36151283],\n",
       "       [ -10.46617457,   -8.64827525, -112.12541872,  -10.46617457],\n",
       "       [  -9.5617925 ,   -7.72553056, -112.12541872,   -9.5617925 ],\n",
       "       [  -8.64827525,   -6.79346521, -112.12541872,   -8.64827525],\n",
       "       [  -7.72553056,   -5.85198506, -112.12541872,   -7.72553056],\n",
       "       [  -6.79346521,   -4.90099501, -112.12541872,   -6.79346521],\n",
       "       [  -5.85198506,   -3.940399  , -112.12541872,   -5.85198506],\n",
       "       [  -4.90099501,   -2.9701    , -112.12541872,   -4.90099501],\n",
       "       [  -3.940399  ,   -1.99      , -112.12541871,   -3.940399  ],\n",
       "       [  -2.9701    ,   -1.99      ,   -1.        ,   -2.9701    ],\n",
       "       [ -12.2478977 , -112.12541872,  -13.12541872,  -13.12541872],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83ycCLWvBTm"
   },
   "source": [
    "Let's use the learned q_table to define the policy. Name the method `policy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "id": "ywaEmwPltP0f"
   },
   "outputs": [],
   "source": [
    "def policy(state): # remove\n",
    "    return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOr6WI1jvuLm"
   },
   "source": [
    "Let's use an Enum to print out nicely which action to take in which state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "WApVVnR3tk7l"
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\n",
    "    LEFT = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1618321750133,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "SYewgCE6t1g7",
    "outputId": "58218484-9290-493d-8f81-e1f76254fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  0  action to take:  DOWN\n",
      "state:  1  action to take:  DOWN\n",
      "state:  2  action to take:  RIGHT\n",
      "state:  3  action to take:  DOWN\n",
      "state:  4  action to take:  RIGHT\n",
      "state:  5  action to take:  DOWN\n",
      "state:  6  action to take:  DOWN\n",
      "state:  7  action to take:  DOWN\n",
      "state:  8  action to take:  RIGHT\n",
      "state:  9  action to take:  RIGHT\n",
      "state:  10  action to take:  RIGHT\n",
      "state:  11  action to take:  RIGHT\n",
      "state:  12  action to take:  RIGHT\n",
      "state:  13  action to take:  RIGHT\n",
      "state:  14  action to take:  RIGHT\n",
      "state:  15  action to take:  RIGHT\n",
      "state:  16  action to take:  DOWN\n",
      "state:  17  action to take:  RIGHT\n",
      "state:  18  action to take:  RIGHT\n",
      "state:  19  action to take:  DOWN\n",
      "state:  20  action to take:  RIGHT\n",
      "state:  21  action to take:  DOWN\n",
      "state:  22  action to take:  DOWN\n",
      "state:  23  action to take:  RIGHT\n",
      "state:  24  action to take:  DOWN\n",
      "state:  25  action to take:  DOWN\n",
      "state:  26  action to take:  DOWN\n",
      "state:  27  action to take:  DOWN\n",
      "state:  28  action to take:  DOWN\n",
      "state:  29  action to take:  DOWN\n",
      "state:  30  action to take:  DOWN\n",
      "state:  31  action to take:  DOWN\n",
      "state:  32  action to take:  DOWN\n",
      "state:  33  action to take:  DOWN\n",
      "state:  34  action to take:  DOWN\n",
      "state:  35  action to take:  RIGHT\n",
      "state:  36  action to take:  LEFT\n",
      "state:  37  action to take:  LEFT\n",
      "state:  38  action to take:  LEFT\n",
      "state:  39  action to take:  LEFT\n",
      "state:  40  action to take:  LEFT\n",
      "state:  41  action to take:  LEFT\n",
      "state:  42  action to take:  LEFT\n",
      "state:  43  action to take:  LEFT\n",
      "state:  44  action to take:  LEFT\n",
      "state:  45  action to take:  LEFT\n",
      "state:  46  action to take:  LEFT\n",
      "state:  47  action to take:  LEFT\n"
     ]
    }
   ],
   "source": [
    "for state in range(state_space_size):\n",
    "    print(\"state: \", state, \" action to take: \", Action(policy(state)).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7wMyAPgyxYR"
   },
   "source": [
    "## Play Cliff Walking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn98l-X6d8Rw"
   },
   "source": [
    "Let's play Cliff Walking for `num_episodes` times and check how well our learned policy does on average. How does it compare to your handcoded policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "id": "hQXIFZyfe1LL"
   },
   "outputs": [],
   "source": [
    "rewards_test = np.zeros(num_episodes)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    for step in range(max_steps_per_episode):\n",
    "        state, reward, terminated, truncated, info = env.step(policy(state))\n",
    "        rewards_test[episode] += reward\n",
    "        done = truncated or terminated \n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1618321839062,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "D4OQGYudfDUB",
    "outputId": "a2008a62-d20b-43aa-8a22-62aa6bbecbb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-13.0"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rewards_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3uOXaA8fKxe"
   },
   "source": [
    "If you want to play Cliff Walking ones and see how the environment evolves you can run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "id": "pm9GIAYQzDCE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26612,
     "status": "ok",
     "timestamp": 1618322057094,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "1XA645-hzGT7",
    "outputId": "c09846b5-608b-46c9-a118-5f6b976ad908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached the goal üèÜ\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CliffWalking-v0\", render_mode=\"human\")\n",
    "state = env.reset()[0]\n",
    "print(env.render())\n",
    "for step in range(max_steps_per_episode):\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)\n",
    "    action = policy(state)       \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()  \n",
    "    done = truncated or terminated \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "if state == 47:\n",
    "    print(\"\\nReached the goal üèÜ\")\n",
    "else:\n",
    "    print(\"\\nFell into the cliff ‚ò†Ô∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ah6pzMUjfzqZ"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 2_ReinforcementLearningIntro_solutions.ipynb",
   "provenance": [
    {
     "file_id": "1_lfz8dLcph3SxvIXFRMEShABtetZPUsU",
     "timestamp": 1640256006360
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
