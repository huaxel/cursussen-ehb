{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_X39pQ5tVP4"
   },
   "source": [
    "# Train an agent to play FrozenLake using Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss-eZTqjte3O"
   },
   "source": [
    "[Gymnasium](https://gymnasium.farama.org) is a toolkit for developing and comparing reinforcement algorithms. It contains several test problem (*environments*) that have a shared interface, allowing you to write general algorithms. \n",
    "\n",
    "Let's start with importing all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%python` not found (But cell magic `%%python` exists, did you mean that instead?).\n"
     ]
    }
   ],
   "source": [
    "%python -m pip install gym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "K5LVzQUirmiF"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K\u001b[2mResolved \u001b[1m129 packages\u001b[0m \u001b[2min 517ms\u001b[0m\u001b[0m                                       \u001b[0m\n",
      "\u001b[2K\u001b[2mAudited \u001b[1m124 packages\u001b[0m \u001b[2min 0.15ms\u001b[0m\u001b[0m                                       \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv add 'gymnasium[classic-control]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfP0PR7_tlLY"
   },
   "source": [
    "One of the environments Gym contains is FrozenLake.\n",
    "\n",
    "    Winter is here. You and your friends were tossing around a frisbee at the\n",
    "    park when you made a wild throw that left the frisbee out in the middle of\n",
    "    the lake. The water is mostly frozen, but there are a few holes where the\n",
    "    ice has melted. If you step into one of those holes, you'll fall into the\n",
    "    freezing water. At this time, there's an international frisbee shortage, so\n",
    "    it's absolutely imperative that you navigate across the lake and retrieve\n",
    "    the disc. However, the ice is slippery, so you won't always move in the\n",
    "    direction you intend.\n",
    "    The surface is described using a grid like the following\n",
    " \n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    " \n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    " \n",
    "    The episode ends when you reach the goal or fall in a hole.\n",
    "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "\n",
    "More info on: https://gymnasium.farama.org/environments/toy_text/frozen_lake/\n",
    "\n",
    "Let's start and create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V90ySjfLtynA"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgsfBm4At2Lg"
   },
   "source": [
    "## Initialize the Q-table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6lM_cuat-9q"
   },
   "source": [
    "Remember: \n",
    "- number of rows: number of states\n",
    "- number of columns: number of actions\n",
    "q-table: np array of dimension (states, actions)\n",
    "\n",
    "add some things on how to make np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WcMatYVCuXM1"
   },
   "outputs": [],
   "source": [
    "state_space_size = env.observation_space.n\n",
    "action_space_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "O7Rr1yo1ujag"
   },
   "outputs": [],
   "source": [
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1618321123871,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "dbuj_-HCunZu",
    "outputId": "e1360b6e-180b-47c1-e7a9-47abe8530f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iZkcf_1vL3Y"
   },
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot-2RUGvOl9"
   },
   "source": [
    "In this section we will initialize the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Booh7w41vfLw"
   },
   "source": [
    "The first one is the *discount factor*. This is a number in [0,1] indicating how much the agent cares about rewards in the future relative to those in the immediate future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "liMcepGyw3uW"
   },
   "outputs": [],
   "source": [
    "discount_factor = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CthvEAPRy0bg"
   },
   "source": [
    "The second parameter is the *learning rate*. This is a number in [0,1] indicating how quickly the agent will adopt the new (learned) Q-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "GiAiP3b0zRnr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATMjtQ1wzZT-"
   },
   "source": [
    "Finally we set the necessary parameters to deal with the trade-off between exploration and exploitation. We have to set\n",
    "- *initial exploration rate*: upper bound for the exploration rate and initial exploration rate, we will use this to update the exploration rate\n",
    "- *minimum exploration rate*: lower bound for the exploration rate, by setting it to a value greater than 0, we make sure there is always a probability for exploration\n",
    "- *exploration rate*: probability that the agent will explore, will be updated after each episode, using exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity, $N(t)$ is the quantity at time step $t$ and $\\lambda$ is the rate of decay.\n",
    "- *exploration rate decay*: how fast or slow does the exploration rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "I9qm0lw2-sn9"
   },
   "outputs": [],
   "source": [
    "initial_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_rate = 1\n",
    "exploration_decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eYlK0-c-45x"
   },
   "source": [
    "We also set number of episodes and maximum number of steps per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DFurhi73_AsW"
   },
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "max_steps_per_episode = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaA0V6O9_TzJ"
   },
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SrazgwEAaN5"
   },
   "source": [
    "Store the total rewards for each episode. This is for diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mmxraf1dekU"
   },
   "source": [
    "If an episode is succesfull this translate to reward 1 if not to reward 0, so we can use this array to check % of successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XuCPM2laARJs"
   },
   "outputs": [],
   "source": [
    "rewards = np.zeros(num_episodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0yUfNqCHP8"
   },
   "source": [
    "In each episode:\n",
    "1.   Reset environment\n",
    "2.   For each step in the episode:\n",
    "  - pick an action $a$ by generating a random float $r$ in $[0,1]$\n",
    "    - if $r > \\epsilon$ we choose the next action by exploitation\n",
    "    - if $r \\leq \\epsilon$ we choose the next action by exploration\n",
    "  - take action $a$ and observe reward $R$ and next state $s'$\n",
    "  - update Q-table \n",
    "  $$ q(s,a) = q(s,a) + \\alpha(R + \\gamma max_{a'} q(s', a') - q(s,a)) $$\n",
    "3. decrease exploration rate proportional to its current value, we will use exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity and $N(t)$ is the quantity at time step $t$.\n",
    "\n",
    "\n",
    "\n",
    "with \n",
    "- $\\epsilon$ the exploration rate,\n",
    "- $\\lambda$ the exploration rate decay,\n",
    "- $\\alpha$ the learning rate and \n",
    "- $\\gamma$ the discount factor.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "zOvIxI_A_V9J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0] # start with a clean slate\n",
    "    reward_episode = 0 # keep track of total reward for this episode\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        # exploration or exploitation? -> we need to pick a random float in 0 and 1\n",
    "        exploration_rate_treshold = random.uniform(0,1)\n",
    "        if exploration_rate_treshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state]) #exploitation: look in row \"state\" which column \"action\" has the highest value\n",
    "        else:\n",
    "            action = env.action_space.sample() #exploration: random action\n",
    "\n",
    "        # take a step in the environment: let's store the new state under a new name since we still need to use the old state\n",
    "        new_state, reward, terminated, truncated , info = env.step(action)\n",
    "        \n",
    "        # terminated = True if environment terminates (eg. due to task completion, failure etc.)\n",
    "        # truncated = True if episode truncates due to a time limit or a reason that is not defined as part of the task.\n",
    "        done = truncated or terminated \n",
    "\n",
    "        # update q-table for current (state, action) pair\n",
    "        q_table[state, action] += learning_rate *\\\n",
    "         (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
    "\n",
    "        # update state\n",
    "        state = new_state\n",
    "        # update reward episode\n",
    "        reward_episode += reward # rewards[episode] += reward\n",
    "\n",
    "        # check if episode ended\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # add reward current episode to rewards array\n",
    "    rewards[episode] = reward_episode\n",
    "\n",
    "    # update exploration rate\n",
    "    exploration_rate = max(initial_exploration_rate * np.exp(- exploration_decay_rate * episode), min_exploration_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsE0vf_ArDFX"
   },
   "source": [
    "Let's print the average reward per thousand episodes, this way we can get an idea about how rewards have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "KduAhbZ3ZuAI"
   },
   "outputs": [],
   "source": [
    "rewards_per_thousand_episodes = np.split(rewards, num_episodes/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after  1000  episodes:  0.286\n",
      "after  2000  episodes:  0.734\n",
      "after  3000  episodes:  0.912\n",
      "after  4000  episodes:  0.959\n",
      "after  5000  episodes:  0.985\n",
      "after  6000  episodes:  0.996\n",
      "after  7000  episodes:  0.987\n",
      "after  8000  episodes:  0.992\n",
      "after  9000  episodes:  0.99\n",
      "after  10000  episodes:  0.991\n"
     ]
    }
   ],
   "source": [
    "count = 1000\n",
    "for reward_group in rewards_per_thousand_episodes:\n",
    "    print(\"after \", count, \" episodes: \", np.average(reward_group))\n",
    "    count+=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvt3Zx5_O-X"
   },
   "source": [
    "Let's also visualize the *learning curve* by plotting the moving average using a window length of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "BnJK6G4Z-9Yg"
   },
   "outputs": [],
   "source": [
    "def moving_average(array, window):\n",
    "    return np.convolve(array, np.ones(window), 'valid') / window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1618321543335,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "C-npvt2E_HIY",
    "outputId": "669283d5-cee7-4a03-a96b-8d2cb7997085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.286, 0.286, 0.286, ..., 0.991, 0.991, 0.991])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_average(rewards, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1618321555999,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "ZYCLeHCm_YwY",
    "outputId": "01d176c1-b242-42f3-8a7b-3631c5a9442b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(999, 10000), moving_average(rewards, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3OyJMQ1ryRs"
   },
   "source": [
    "## Optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOCvgWWdqYyw"
   },
   "source": [
    "Let's print the q_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1618321716577,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "6pXJnq4KWDtR",
    "outputId": "c83ec5f1-1fc0-45e7-89e9-8d801049f427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94148015, 0.95099005, 0.93206535, 0.94148015],\n",
       "       [0.94148015, 0.        , 0.90074647, 0.90860853],\n",
       "       [0.6613915 , 0.96480805, 0.35176677, 0.4946806 ],\n",
       "       [0.63312095, 0.        , 0.159837  , 0.0587711 ],\n",
       "       [0.95099005, 0.96059601, 0.        , 0.94148015],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.98009996, 0.        , 0.85110797],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.96059601, 0.        , 0.970299  , 0.95099005],\n",
       "       [0.96059597, 0.98009999, 0.9801    , 0.        ],\n",
       "       [0.97029875, 0.99      , 0.        , 0.97029844],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.86221802, 0.99      , 0.9130117 ],\n",
       "       [0.98009912, 0.98999998, 1.        , 0.98009962],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83ycCLWvBTm"
   },
   "source": [
    "Let's use the learned q_table to define the policy. Name the method `policy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "ywaEmwPltP0f"
   },
   "outputs": [],
   "source": [
    "def policy(state): # remove\n",
    "    return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOr6WI1jvuLm"
   },
   "source": [
    "Let's use an Enum to print out nicely which action to take in which state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "WApVVnR3tk7l"
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\n",
    "    LEFT = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1618321750133,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "SYewgCE6t1g7",
    "outputId": "58218484-9290-493d-8f81-e1f76254fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  0  action to take:  DOWN\n",
      "state:  1  action to take:  LEFT\n",
      "state:  2  action to take:  DOWN\n",
      "state:  3  action to take:  LEFT\n",
      "state:  4  action to take:  DOWN\n",
      "state:  5  action to take:  LEFT\n",
      "state:  6  action to take:  DOWN\n",
      "state:  7  action to take:  LEFT\n",
      "state:  8  action to take:  RIGHT\n",
      "state:  9  action to take:  RIGHT\n",
      "state:  10  action to take:  DOWN\n",
      "state:  11  action to take:  LEFT\n",
      "state:  12  action to take:  LEFT\n",
      "state:  13  action to take:  RIGHT\n",
      "state:  14  action to take:  RIGHT\n",
      "state:  15  action to take:  LEFT\n"
     ]
    }
   ],
   "source": [
    "for state in range(state_space_size):\n",
    "    print(\"state: \", state, \" action to take: \", Action(policy(state)).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNYFkJPcvI1P"
   },
   "source": [
    "Remember the surface looks as follows\n",
    " \n",
    " ```\n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    " \n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    "```\n",
    "\n",
    "It seems the best action to state in state 1 (upper left) is to go left. This might seem a strange choice. Why is this?\n",
    "\n",
    "**answer** this is because the agent has learned that it goes down first it might end up somewhere where he didn't want to end up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7wMyAPgyxYR"
   },
   "source": [
    "## Play FrozenLake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn98l-X6d8Rw"
   },
   "source": [
    "Let's play FrozenLake for `num_episodes` times and check how well our learned policy does on average. How does it compare to your handcoded policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "hQXIFZyfe1LL"
   },
   "outputs": [],
   "source": [
    "rewards_test = np.zeros(num_episodes)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    for step in range(max_steps_per_episode):\n",
    "        state, reward, terminated, truncated, info = env.step(policy(state))\n",
    "        rewards_test[episode] += reward\n",
    "        done = truncated or terminated \n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1618321839062,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "D4OQGYudfDUB",
    "outputId": "a2008a62-d20b-43aa-8a22-62aa6bbecbb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rewards_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3uOXaA8fKxe"
   },
   "source": [
    "If you want to play FrozenLake ones and see how the environment evolves you can run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "pm9GIAYQzDCE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26612,
     "status": "ok",
     "timestamp": 1618322057094,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "1XA645-hzGT7",
    "outputId": "c09846b5-608b-46c9-a118-5f6b976ad908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached the goal üèÜ\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"human\")\n",
    "state = env.reset()[0]\n",
    "print(env.render())\n",
    "for step in range(max_steps_per_episode):\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)\n",
    "    action = policy(state)       \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()  \n",
    "    done = truncated or terminated \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "if state == 15:\n",
    "    print(\"\\nReached the goal üèÜ\")\n",
    "else:\n",
    "    print(\"\\nFell into a hole ‚ò†Ô∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ah6pzMUjfzqZ"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 2_ReinforcementLearningIntro_solutions.ipynb",
   "provenance": [
    {
     "file_id": "1_lfz8dLcph3SxvIXFRMEShABtetZPUsU",
     "timestamp": 1640256006360
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
