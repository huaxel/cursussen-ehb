{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_X39pQ5tVP4"
   },
   "source": [
    "# Train an agent to play Cliff Walking using Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss-eZTqjte3O"
   },
   "source": [
    "[Gymnasium](https://gymnasium.farama.org) is a toolkit for developing and comparing reinforcement algorithms. It contains several test problem (*environments*) that have a shared interface, allowing you to write general algorithms. \n",
    "\n",
    "Let's start with importing all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "K5LVzQUirmiF"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium[classic-control] in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gymnasium[classic-control]) (2.2.3)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gymnasium[classic-control]) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gymnasium[classic-control]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gymnasium[classic-control]) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gymnasium[classic-control]) (2.6.1)\n",
      "Requirement already satisfied: gym in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (0.26.2)\n",
      "Requirement already satisfied: numpy in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (2.2.3)\n",
      "Collecting numpy\n",
      "  Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gym) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in /Users/juanbenjumea/coding/EHB/AIE/.venv/lib/python3.12/site-packages (from gym) (0.0.8)\n",
      "Downloading numpy-2.2.5-cp312-cp312-macosx_14_0_arm64.whl (5.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.3\n",
      "    Uninstalling numpy-2.2.3:\n",
      "      Successfully uninstalled numpy-2.2.3\n",
      "Successfully installed numpy-2.2.5\n"
     ]
    }
   ],
   "source": [
    "!pip install 'gymnasium[classic-control]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfP0PR7_tlLY"
   },
   "source": [
    "## Description of the game\n",
    "\n",
    "The Cliff Walking environment in Gymnasium (previously part of OpenAI Gym) is like this:\n",
    "\n",
    "Imagine a grid — like a checkerboard — where you start in the bottom-left corner.\n",
    "Your goal is to reach the bottom-right corner.\n",
    "But! Between you and the goal, along the bottom row, is a cliff — a dangerous area.\n",
    "If you step into the cliff, you \"fall off,\" get a big negative reward (penalty), and you’re sent back to the start.\n",
    "If you manage to walk safely around the cliff and reach the goal, you win.\n",
    "More details:\n",
    "\n",
    "Each move (up, down, left, right) gives a small penalty (like -1 reward) because they want to encourage you to find the fastest route.\n",
    "Falling off the cliff gives a huge penalty (like -100).\n",
    "The \"safe\" path is usually to move right across the second-to-last row, and only at the end move down carefully to the goal.\n",
    "\n",
    "More info on: https://gymnasium.farama.org/environments/toy_text/cliff_walking/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "V90ySjfLtynA"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"CliffWalking-v0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgsfBm4At2Lg"
   },
   "source": [
    "## Initialize the Q-table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6lM_cuat-9q"
   },
   "source": [
    "Remember: \n",
    "- number of rows: number of states\n",
    "- number of columns: number of actions\n",
    "q-table: np array of dimension (states, actions)\n",
    "\n",
    "add some things on how to make np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "WcMatYVCuXM1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State space size: 48\n"
     ]
    }
   ],
   "source": [
    "state_space_size = env.observation_space.n\n",
    "action_space_size = env.action_space.n\n",
    "print(f\"State space size: {state_space_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q-table shape: (48, 4)\n"
     ]
    }
   ],
   "source": [
    "q_table = np.zeros((state_space_size, action_space_size))\n",
    "print(f\"Q-table shape: {q_table.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "liMcepGyw3uW"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iZkcf_1vL3Y"
   },
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "discount_factor = 0.99\n",
    "learning_rate = 0.1\n",
    "\n",
    "initial_exploration_rate = 1.0\n",
    "min_exploration_rate = 0.01\n",
    "exploration_rate = 1\n",
    "exploration_decay_rate = 0.001\n",
    "\n",
    "num_episodes = 10000\n",
    "max_steps_per_episode = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaA0V6O9_TzJ"
   },
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SrazgwEAaN5"
   },
   "source": [
    "Store the total rewards for each episode. This is for diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "XuCPM2laARJs"
   },
   "outputs": [],
   "source": [
    "rewards = np.zeros(num_episodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0yUfNqCHP8"
   },
   "source": [
    "In each episode:\n",
    "1.   Reset environment\n",
    "2.   For each step in the episode:\n",
    "  - pick an action $a$ by generating a random float $r$ in $[0,1]$\n",
    "    - if $r > \\epsilon$ we choose the next action by exploitation\n",
    "    - if $r \\leq \\epsilon$ we choose the next action by exploration\n",
    "  - take action $a$ and observe reward $R$ and next state $s'$\n",
    "  - update Q-table \n",
    "  $$ q(s,a) = q(s,a) + \\alpha(R + \\gamma max_{a'} q(s', a') - q(s,a)) $$\n",
    "3. decrease exploration rate proportional to its current value, we will use exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity and $N(t)$ is the quantity at time step $t$.\n",
    "\n",
    "\n",
    "\n",
    "with \n",
    "- $\\epsilon$ the exploration rate,\n",
    "- $\\lambda$ the exploration rate decay,\n",
    "- $\\alpha$ the learning rate and \n",
    "- $\\gamma$ the discount factor.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zOvIxI_A_V9J"
   },
   "outputs": [],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    reward_episode = 0\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        # Exploration vs Exploitation\n",
    "        exploration_rate_threshold = random.uniform(0, 1)\n",
    "        if exploration_rate_threshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state])\n",
    "        else:\n",
    "            action = env.action_space.sample()\n",
    "        # Take action\n",
    "        new_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "        done = terminated or truncated\n",
    "\n",
    "        # Update Q-table\n",
    "        q_table[state, action] += learning_rate * (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
    "\n",
    "        # Update state\n",
    "        state = new_state\n",
    "        reward_episode += reward\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "        rewards[episode] = reward_episode\n",
    "\n",
    "    # Exploration rate decay\n",
    "    exploration_rate = max(initial_exploration_rate * np.exp(-exploration_decay_rate * episode), min_exploration_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsE0vf_ArDFX"
   },
   "source": [
    "Let's print the average reward per thousand episodes, this way we can get an idea about how rewards have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "KduAhbZ3ZuAI"
   },
   "outputs": [],
   "source": [
    "rewards_per_thousand_episodes = np.split(rewards, num_episodes / 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvt3Zx5_O-X"
   },
   "source": [
    "Let's also visualize the *learning curve* by plotting the moving average using a window length of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "BnJK6G4Z-9Yg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after  1000  episodes:  -551.304\n",
      "after  2000  episodes:  -135.774\n",
      "after  3000  episodes:  -44.147\n",
      "after  4000  episodes:  -22.1\n",
      "after  5000  episodes:  -14.823\n",
      "after  6000  episodes:  -14.485\n",
      "after  7000  episodes:  -14.537\n",
      "after  8000  episodes:  -15.776\n",
      "after  9000  episodes:  -14.712\n",
      "after  10000  episodes:  -14.252\n"
     ]
    }
   ],
   "source": [
    "count = 1000\n",
    "for r in rewards_per_thousand_episodes:\n",
    "    print(\"after \", count, \" episodes: \", np.average(r))    \n",
    "    count += 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def moving_average(array, window):\n",
    "    return np.convolve(array, np.ones(window), 'valid') / window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-551.304, -550.829, -550.056, ...,  -14.252,  -14.252,  -14.252],\n",
       "      shape=(9001,))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_average(rewards, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(999, 10000), moving_average(rewards, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3OyJMQ1ryRs"
   },
   "source": [
    "## Optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOCvgWWdqYyw"
   },
   "source": [
    "Let's print the q_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1618321716577,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "6pXJnq4KWDtR",
    "outputId": "c83ec5f1-1fc0-45e7-89e9-8d801049f427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -13.49888488,  -13.10117112,  -13.10205649,  -13.60827457],\n",
       "       [ -12.90115738,  -12.24387236,  -12.24409359,  -13.6911842 ],\n",
       "       [ -12.13385665,  -11.3605006 ,  -11.3605481 ,  -13.04101356],\n",
       "       [ -11.32215161,  -10.465809  ,  -10.4658017 ,  -12.1579141 ],\n",
       "       [ -10.45560886,   -9.56161511,   -9.56162685,  -11.31610919],\n",
       "       [  -9.54574599,   -8.64819905,   -8.64820004,  -10.45156803],\n",
       "       [  -8.63600084,   -7.72548687,   -7.72549023,   -9.54811828],\n",
       "       [  -7.71450206,   -6.79343815,   -6.79343973,   -8.63322037],\n",
       "       [  -6.77695765,   -5.851973  ,   -5.85197332,   -7.70640518],\n",
       "       [  -5.77949288,   -4.9009896 ,   -4.90098976,   -6.7616875 ],\n",
       "       [  -4.88536742,   -3.94039749,   -3.94039742,   -5.78799926],\n",
       "       [  -3.92493247,   -3.89851901,   -2.97009999,   -4.85149692],\n",
       "       [ -13.94450489,  -12.2478977 ,  -12.2478977 ,  -13.12416026],\n",
       "       [ -13.11659227,  -11.36151283,  -11.36151283,  -13.12513457],\n",
       "       [ -12.2451352 ,  -10.46617457,  -10.46617457,  -12.24777613],\n",
       "       [ -11.36050628,   -9.5617925 ,   -9.5617925 ,  -11.36133138],\n",
       "       [ -10.46535954,   -8.64827525,   -8.64827525,  -10.4661386 ],\n",
       "       [  -9.56145934,   -7.72553056,   -7.72553056,   -9.561783  ],\n",
       "       [  -8.64788183,   -6.79346521,   -6.79346521,   -8.64826442],\n",
       "       [  -7.72490678,   -5.85198506,   -5.85198506,   -7.72549515],\n",
       "       [  -6.79210915,   -4.90099501,   -4.90099501,   -6.79336706],\n",
       "       [  -5.85138082,   -3.940399  ,   -3.940399  ,   -5.85191686],\n",
       "       [  -4.90031968,   -2.9701    ,   -2.9701    ,   -4.90081447],\n",
       "       [  -3.93932084,   -2.97007812,   -1.99      ,   -3.94034834],\n",
       "       [ -13.12541872,  -11.36151283,  -13.12541872,  -12.2478977 ],\n",
       "       [ -12.2478977 ,  -10.46617457, -112.12541872,  -12.2478977 ],\n",
       "       [ -11.36151283,   -9.5617925 , -112.12541872,  -11.36151283],\n",
       "       [ -10.46617457,   -8.64827525, -112.12541872,  -10.46617457],\n",
       "       [  -9.5617925 ,   -7.72553056, -112.12541872,   -9.5617925 ],\n",
       "       [  -8.64827525,   -6.79346521, -112.12541872,   -8.64827525],\n",
       "       [  -7.72553056,   -5.85198506, -112.12541872,   -7.72553056],\n",
       "       [  -6.79346521,   -4.90099501, -112.12541872,   -6.79346521],\n",
       "       [  -5.85198506,   -3.940399  , -112.12541872,   -5.85198506],\n",
       "       [  -4.90099501,   -2.9701    , -112.12541871,   -4.90099501],\n",
       "       [  -3.940399  ,   -1.99      , -112.12541871,   -3.940399  ],\n",
       "       [  -2.9701    ,   -1.99      ,   -1.        ,   -2.9701    ],\n",
       "       [ -12.2478977 , -112.12541872,  -13.12541872,  -13.12541872],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ],\n",
       "       [   0.        ,    0.        ,    0.        ,    0.        ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83ycCLWvBTm"
   },
   "source": [
    "Let's use the learned q_table to define the policy. Name the method `policy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "ywaEmwPltP0f"
   },
   "outputs": [],
   "source": [
    "def policy(state):\n",
    "    return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOr6WI1jvuLm"
   },
   "source": [
    "Let's use an Enum to print out nicely which action to take in which state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\n",
    "    LEFT = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  0  action to take:  DOWN\n",
      "state:  1  action to take:  DOWN\n",
      "state:  2  action to take:  DOWN\n",
      "state:  3  action to take:  RIGHT\n",
      "state:  4  action to take:  DOWN\n",
      "state:  5  action to take:  DOWN\n",
      "state:  6  action to take:  DOWN\n",
      "state:  7  action to take:  DOWN\n",
      "state:  8  action to take:  DOWN\n",
      "state:  9  action to take:  DOWN\n",
      "state:  10  action to take:  RIGHT\n",
      "state:  11  action to take:  RIGHT\n",
      "state:  12  action to take:  DOWN\n",
      "state:  13  action to take:  DOWN\n",
      "state:  14  action to take:  RIGHT\n",
      "state:  15  action to take:  DOWN\n",
      "state:  16  action to take:  RIGHT\n",
      "state:  17  action to take:  DOWN\n",
      "state:  18  action to take:  RIGHT\n",
      "state:  19  action to take:  RIGHT\n",
      "state:  20  action to take:  DOWN\n",
      "state:  21  action to take:  DOWN\n",
      "state:  22  action to take:  DOWN\n",
      "state:  23  action to take:  RIGHT\n",
      "state:  24  action to take:  DOWN\n",
      "state:  25  action to take:  DOWN\n",
      "state:  26  action to take:  DOWN\n",
      "state:  27  action to take:  DOWN\n",
      "state:  28  action to take:  DOWN\n",
      "state:  29  action to take:  DOWN\n",
      "state:  30  action to take:  DOWN\n",
      "state:  31  action to take:  DOWN\n",
      "state:  32  action to take:  DOWN\n",
      "state:  33  action to take:  DOWN\n",
      "state:  34  action to take:  DOWN\n",
      "state:  35  action to take:  RIGHT\n",
      "state:  36  action to take:  LEFT\n",
      "state:  37  action to take:  LEFT\n",
      "state:  38  action to take:  LEFT\n",
      "state:  39  action to take:  LEFT\n",
      "state:  40  action to take:  LEFT\n",
      "state:  41  action to take:  LEFT\n",
      "state:  42  action to take:  LEFT\n",
      "state:  43  action to take:  LEFT\n",
      "state:  44  action to take:  LEFT\n",
      "state:  45  action to take:  LEFT\n",
      "state:  46  action to take:  LEFT\n",
      "state:  47  action to take:  LEFT\n"
     ]
    }
   ],
   "source": [
    "for state in range(state_space_size):\n",
    "    print(\"state: \", state, \" action to take: \", Action(policy(state)).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7wMyAPgyxYR"
   },
   "source": [
    "## Play Cliff Walking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn98l-X6d8Rw"
   },
   "source": [
    "Let's play Cliff Walking for `num_episodes` times and check how well our learned policy does on average. How does it compare to your handcoded policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "hQXIFZyfe1LL"
   },
   "outputs": [],
   "source": [
    "rewards_test = np.zeros(num_episodes)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    for step in range(max_steps_per_episode):\n",
    "        state, reward, terminated, truncated, info = env.step(policy(state))\n",
    "        rewards_test[episode] += reward\n",
    "        done = terminated or truncated\n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(-13.0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rewards_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3uOXaA8fKxe"
   },
   "source": [
    "Play the cliff walking game in a (rendered) human environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "pm9GIAYQzDCE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26612,
     "status": "ok",
     "timestamp": 1618322057094,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "1XA645-hzGT7",
    "outputId": "c09846b5-608b-46c9-a118-5f6b976ad908"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'bool8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_steps_per_episode):\n\u001b[1;32m      5\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.5\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     state, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     terminated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(terminated)\n\u001b[1;32m      8\u001b[0m     truncated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mbool\u001b[39m(truncated)\n",
      "File \u001b[0;32m~/coding/EHB/AIE/.venv/lib/python3.12/site-packages/gym/wrappers/order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/coding/EHB/AIE/.venv/lib/python3.12/site-packages/gym/wrappers/env_checker.py:37\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchecked_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m---> 37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43menv_step_passive_checker\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mstep(action)\n",
      "File \u001b[0;32m~/coding/EHB/AIE/.venv/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233\u001b[0m, in \u001b[0;36menv_step_passive_checker\u001b[0;34m(env, action)\u001b[0m\n\u001b[1;32m    230\u001b[0m obs, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m result\n\u001b[1;32m    232\u001b[0m \u001b[38;5;66;03m# np.bool is actual python bool not np boolean type, therefore bool_ or bool8\u001b[39;00m\n\u001b[0;32m--> 233\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(terminated, (\u001b[38;5;28mbool\u001b[39m, \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbool8\u001b[49m)):\n\u001b[1;32m    234\u001b[0m     logger\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    235\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpects `terminated` signal to be a boolean, actual type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(terminated)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    236\u001b[0m     )\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(truncated, (\u001b[38;5;28mbool\u001b[39m, np\u001b[38;5;241m.\u001b[39mbool8)):\n",
      "File \u001b[0;32m~/coding/EHB/AIE/.venv/lib/python3.12/site-packages/numpy/__init__.py:414\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    411\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mchar\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mchar\u001b[39;00m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m char\u001b[38;5;241m.\u001b[39mchararray\n\u001b[0;32m--> 414\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    415\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'bool8'"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"CliffWalking-v0\", render_mode=\"human\")\n",
    "state = env.reset()[0]\n",
    "prind(env.render())\n",
    "\n",
    "for step in range(max_steps_per_episode):\n",
    "    time.sleep(0.5)\n",
    "    state, reward, terminated, truncated, info = env.step(policy(state))\n",
    "    terminated = bool(terminated)\n",
    "    truncated = bool(truncated)\n",
    "    frame = env.render()  # This returns the current frame as an array\n",
    "    done = terminated or truncated\n",
    "    if done:\n",
    "        break\n",
    "\n",
    "if state == 47:\n",
    "    print(\"You reached the goal!\")\n",
    "else:\n",
    "    print(\"You fell off the cliff!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ah6pzMUjfzqZ"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 2_ReinforcementLearningIntro_solutions.ipynb",
   "provenance": [
    {
     "file_id": "1_lfz8dLcph3SxvIXFRMEShABtetZPUsU",
     "timestamp": 1640256006360
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "project"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
