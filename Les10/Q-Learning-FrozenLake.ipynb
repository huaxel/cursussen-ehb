{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R_X39pQ5tVP4"
   },
   "source": [
    "# Train an agent to play FrozenLake using Q-learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ss-eZTqjte3O"
   },
   "source": [
    "[Gymnasium](https://gymnasium.farama.org) is a toolkit for developing and comparing reinforcement algorithms. It contains several test problem (*environments*) that have a shared interface, allowing you to write general algorithms. \n",
    "\n",
    "Let's start with importing all necessary dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "K5LVzQUirmiF"
   },
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import random\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gymnasium[classic-control]\n",
      "  Downloading gymnasium-1.1.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (3.0.0)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in /opt/anaconda3/lib/python3.12/site-packages (from gymnasium[classic-control]) (4.11.0)\n",
      "Collecting farama-notifications>=0.0.1 (from gymnasium[classic-control])\n",
      "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
      "Collecting pygame>=2.1.3 (from gymnasium[classic-control])\n",
      "  Downloading pygame-2.6.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
      "Downloading pygame-2.6.1-cp312-cp312-macosx_11_0_arm64.whl (12.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading gymnasium-1.1.1-py3-none-any.whl (965 kB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m965.4/965.4 kB\u001b[0m \u001b[31m993.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: farama-notifications, pygame, gymnasium\n",
      "Successfully installed farama-notifications-0.0.4 gymnasium-1.1.1 pygame-2.6.1\n"
     ]
    }
   ],
   "source": [
    "!pip install 'gymnasium[classic-control]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WfP0PR7_tlLY"
   },
   "source": [
    "One of the environments Gym contains is FrozenLake.\n",
    "\n",
    "    Winter is here. You and your friends were tossing around a frisbee at the\n",
    "    park when you made a wild throw that left the frisbee out in the middle of\n",
    "    the lake. The water is mostly frozen, but there are a few holes where the\n",
    "    ice has melted. If you step into one of those holes, you'll fall into the\n",
    "    freezing water. At this time, there's an international frisbee shortage, so\n",
    "    it's absolutely imperative that you navigate across the lake and retrieve\n",
    "    the disc. However, the ice is slippery, so you won't always move in the\n",
    "    direction you intend.\n",
    "    The surface is described using a grid like the following\n",
    " \n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    " \n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    " \n",
    "    The episode ends when you reach the goal or fall in a hole.\n",
    "    You receive a reward of 1 if you reach the goal, and zero otherwise.\n",
    "\n",
    "More info on: https://gymnasium.farama.org/environments/toy_text/frozen_lake/\n",
    "\n",
    "Let's start and create the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "V90ySjfLtynA"
   },
   "outputs": [],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cgsfBm4At2Lg"
   },
   "source": [
    "## Initialize the Q-table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x6lM_cuat-9q"
   },
   "source": [
    "Remember: \n",
    "- number of rows: number of states\n",
    "- number of columns: number of actions\n",
    "q-table: np array of dimension (states, actions)\n",
    "\n",
    "add some things on how to make np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WcMatYVCuXM1"
   },
   "outputs": [],
   "source": [
    "state_space_size = env.observation_space.n\n",
    "action_space_size = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "O7Rr1yo1ujag"
   },
   "outputs": [],
   "source": [
    "q_table = np.zeros((state_space_size, action_space_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1143,
     "status": "ok",
     "timestamp": 1618321123871,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "dbuj_-HCunZu",
    "outputId": "e1360b6e-180b-47c1-e7a9-47abe8530f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0iZkcf_1vL3Y"
   },
   "source": [
    "## Set the hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zot-2RUGvOl9"
   },
   "source": [
    "In this section we will initialize the hyperparameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Booh7w41vfLw"
   },
   "source": [
    "The first one is the *discount factor*. This is a number in [0,1] indicating how much the agent cares about rewards in the future relative to those in the immediate future. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "liMcepGyw3uW"
   },
   "outputs": [],
   "source": [
    "discount_factor = 0.99"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CthvEAPRy0bg"
   },
   "source": [
    "The second parameter is the *learning rate*. This is a number in [0,1] indicating how quickly the agent will adopt the new (learned) Q-value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "GiAiP3b0zRnr"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ATMjtQ1wzZT-"
   },
   "source": [
    "Finally we set the necessary parameters to deal with the trade-off between exploration and exploitation. We have to set\n",
    "- *initial exploration rate*: upper bound for the exploration rate and initial exploration rate, we will use this to update the exploration rate\n",
    "- *minimum exploration rate*: lower bound for the exploration rate, by setting it to a value greater than 0, we make sure there is always a probability for exploration\n",
    "- *exploration rate*: probability that the agent will explore, will be updated after each episode, using exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity, $N(t)$ is the quantity at time step $t$ and $\\lambda$ is the rate of decay.\n",
    "- *exploration rate decay*: how fast or slow does the exploration rate decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "I9qm0lw2-sn9"
   },
   "outputs": [],
   "source": [
    "initial_exploration_rate = 1\n",
    "min_exploration_rate = 0.01\n",
    "exploration_rate = 1\n",
    "exploration_decay_rate = 0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1eYlK0-c-45x"
   },
   "source": [
    "We also set number of episodes and maximum number of steps per episode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DFurhi73_AsW"
   },
   "outputs": [],
   "source": [
    "num_episodes = 10000\n",
    "max_steps_per_episode = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaA0V6O9_TzJ"
   },
   "source": [
    "## Train the agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3SrazgwEAaN5"
   },
   "source": [
    "Store the total rewards for each episode. This is for diagnostics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Mmxraf1dekU"
   },
   "source": [
    "If an episode is succesfull this translate to reward 1 if not to reward 0, so we can use this array to check % of successes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "XuCPM2laARJs"
   },
   "outputs": [],
   "source": [
    "rewards = np.zeros(num_episodes) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zy0yUfNqCHP8"
   },
   "source": [
    "In each episode:\n",
    "1.   Reset environment\n",
    "2.   For each step in the episode:\n",
    "  - pick an action $a$ by generating a random float $r$ in $[0,1]$\n",
    "    - if $r > \\epsilon$ we choose the next action by exploitation\n",
    "    - if $r \\leq \\epsilon$ we choose the next action by exploration\n",
    "  - take action $a$ and observe reward $R$ and next state $s'$\n",
    "  - update Q-table \n",
    "  $$ q(s,a) = q(s,a) + \\alpha(R + \\gamma max_{a'} q(s', a') - q(s,a)) $$\n",
    "3. decrease exploration rate proportional to its current value, we will use exponential decay: \n",
    "$$N(t) = N_0 e^{-\\lambda t}$$\n",
    "where $N_0$ is the initial quantity and $N(t)$ is the quantity at time step $t$.\n",
    "\n",
    "\n",
    "\n",
    "with \n",
    "- $\\epsilon$ the exploration rate,\n",
    "- $\\lambda$ the exploration rate decay,\n",
    "- $\\alpha$ the learning rate and \n",
    "- $\\gamma$ the discount factor.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zOvIxI_A_V9J"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0] # start with a clean slate\n",
    "    reward_episode = 0 # keep track of total reward for this episode\n",
    "\n",
    "    for step in range(max_steps_per_episode):\n",
    "        # exploration or exploitation? -> we need to pick a random float in 0 and 1\n",
    "        exploration_rate_treshold = random.uniform(0,1)\n",
    "        if exploration_rate_treshold > exploration_rate:\n",
    "            action = np.argmax(q_table[state]) #exploitation: look in row \"state\" which column \"action\" has the highest value\n",
    "        else:\n",
    "            action = env.action_space.sample() #exploration: random action\n",
    "\n",
    "        # take a step in the environment: let's store the new state under a new name since we still need to use the old state\n",
    "        new_state, reward, terminated, truncated , info = env.step(action)\n",
    "        \n",
    "        # terminated = True if environment terminates (eg. due to task completion, failure etc.)\n",
    "        # truncated = True if episode truncates due to a time limit or a reason that is not defined as part of the task.\n",
    "        done = truncated or terminated \n",
    "\n",
    "        # update q-table for current (state, action) pair\n",
    "        q_table[state, action] += learning_rate *\\\n",
    "         (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
    "\n",
    "        # update state\n",
    "        state = new_state\n",
    "        # update reward episode\n",
    "        reward_episode += reward # rewards[episode] += reward\n",
    "\n",
    "        # check if episode ended\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    # add reward current episode to rewards array\n",
    "    rewards[episode] = reward_episode\n",
    "\n",
    "    # update exploration rate\n",
    "    exploration_rate = max(initial_exploration_rate * np.exp(- exploration_decay_rate * episode), min_exploration_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IsE0vf_ArDFX"
   },
   "source": [
    "Let's print the average reward per thousand episodes, this way we can get an idea about how rewards have changed over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "KduAhbZ3ZuAI"
   },
   "outputs": [],
   "source": [
    "rewards_per_thousand_episodes = np.split(rewards, num_episodes/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after  1000  episodes:  0.225\n",
      "after  2000  episodes:  0.731\n",
      "after  3000  episodes:  0.911\n",
      "after  4000  episodes:  0.969\n",
      "after  5000  episodes:  0.99\n",
      "after  6000  episodes:  0.99\n",
      "after  7000  episodes:  0.984\n",
      "after  8000  episodes:  0.993\n",
      "after  9000  episodes:  0.989\n",
      "after  10000  episodes:  0.984\n"
     ]
    }
   ],
   "source": [
    "count = 1000\n",
    "for reward_group in rewards_per_thousand_episodes:\n",
    "    print(\"after \", count, \" episodes: \", np.average(reward_group))\n",
    "    count+=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THvt3Zx5_O-X"
   },
   "source": [
    "Let's also visualize the *learning curve* by plotting the moving average using a window length of 1000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "BnJK6G4Z-9Yg"
   },
   "outputs": [],
   "source": [
    "def moving_average(array, window):\n",
    "    return np.convolve(array, np.ones(window), 'valid') / window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 800,
     "status": "ok",
     "timestamp": 1618321543335,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "C-npvt2E_HIY",
    "outputId": "669283d5-cee7-4a03-a96b-8d2cb7997085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.225, 0.225, 0.225, ..., 0.984, 0.984, 0.984])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_average(rewards, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 778,
     "status": "ok",
     "timestamp": 1618321555999,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "ZYCLeHCm_YwY",
    "outputId": "01d176c1-b242-42f3-8a7b-3631c5a9442b"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(np.arange(999, 10000), moving_average(rewards, 1000))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J3OyJMQ1ryRs"
   },
   "source": [
    "## Optimal policy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iOCvgWWdqYyw"
   },
   "source": [
    "Let's print the q_table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 591,
     "status": "ok",
     "timestamp": 1618321716577,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "6pXJnq4KWDtR",
    "outputId": "c83ec5f1-1fc0-45e7-89e9-8d801049f427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.94148014, 0.95099005, 0.93206416, 0.94148015],\n",
       "       [0.94148002, 0.        , 0.42041083, 0.83465054],\n",
       "       [0.68610035, 0.07650416, 0.00341097, 0.00856412],\n",
       "       [0.03445428, 0.        , 0.        , 0.        ],\n",
       "       [0.95099   , 0.96059601, 0.        , 0.94148015],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.85482199, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.960596  , 0.        , 0.970299  , 0.95099004],\n",
       "       [0.96059594, 0.9801    , 0.98009869, 0.        ],\n",
       "       [0.80386836, 0.99      , 0.        , 0.57481703],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.98009925, 0.99      , 0.97029889],\n",
       "       [0.9800982 , 0.9899999 , 1.        , 0.98009259],\n",
       "       [0.        , 0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y83ycCLWvBTm"
   },
   "source": [
    "Let's use the learned q_table to define the policy. Name the method `policy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "id": "ywaEmwPltP0f"
   },
   "outputs": [],
   "source": [
    "def policy(state): # remove\n",
    "    return np.argmax(q_table[state])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nOr6WI1jvuLm"
   },
   "source": [
    "Let's use an Enum to print out nicely which action to take in which state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "WApVVnR3tk7l"
   },
   "outputs": [],
   "source": [
    "class Action(Enum):\n",
    "\n",
    "    LEFT = 0\n",
    "    DOWN = 1\n",
    "    RIGHT = 2\n",
    "    UP = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 468,
     "status": "ok",
     "timestamp": 1618321750133,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "SYewgCE6t1g7",
    "outputId": "58218484-9290-493d-8f81-e1f76254fe2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state:  0  action to take:  DOWN\n",
      "state:  1  action to take:  LEFT\n",
      "state:  2  action to take:  LEFT\n",
      "state:  3  action to take:  LEFT\n",
      "state:  4  action to take:  DOWN\n",
      "state:  5  action to take:  LEFT\n",
      "state:  6  action to take:  DOWN\n",
      "state:  7  action to take:  LEFT\n",
      "state:  8  action to take:  RIGHT\n",
      "state:  9  action to take:  DOWN\n",
      "state:  10  action to take:  DOWN\n",
      "state:  11  action to take:  LEFT\n",
      "state:  12  action to take:  LEFT\n",
      "state:  13  action to take:  RIGHT\n",
      "state:  14  action to take:  RIGHT\n",
      "state:  15  action to take:  LEFT\n"
     ]
    }
   ],
   "source": [
    "for state in range(state_space_size):\n",
    "    print(\"state: \", state, \" action to take: \", Action(policy(state)).name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oNYFkJPcvI1P"
   },
   "source": [
    "Remember the surface looks as follows\n",
    " \n",
    " ```\n",
    "        SFFF\n",
    "        FHFH\n",
    "        FFFH\n",
    "        HFFG\n",
    " \n",
    "    S : starting point, safe\n",
    "    F : frozen surface, safe\n",
    "    H : hole, fall to your doom\n",
    "    G : goal, where the frisbee is located\n",
    "```\n",
    "\n",
    "It seems the best action to state in state 1 (upper left) is to go left. This might seem a strange choice. Why is this?\n",
    "\n",
    "**answer** this is because the agent has learned that it goes down first it might end up somewhere where he didn't want to end up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x7wMyAPgyxYR"
   },
   "source": [
    "## Play FrozenLake"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sn98l-X6d8Rw"
   },
   "source": [
    "Let's play FrozenLake for `num_episodes` times and check how well our learned policy does on average. How does it compare to your handcoded policy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "id": "hQXIFZyfe1LL"
   },
   "outputs": [],
   "source": [
    "rewards_test = np.zeros(num_episodes)\n",
    "\n",
    "for episode in range(num_episodes):\n",
    "    state = env.reset()[0]\n",
    "    for step in range(max_steps_per_episode):\n",
    "        state, reward, terminated, truncated, info = env.step(policy(state))\n",
    "        rewards_test[episode] += reward\n",
    "        done = truncated or terminated \n",
    "        if done:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1618321839062,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "D4OQGYudfDUB",
    "outputId": "a2008a62-d20b-43aa-8a22-62aa6bbecbb1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(rewards_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g3uOXaA8fKxe"
   },
   "source": [
    "If you want to play FrozenLake ones and see how the environment evolves you can run the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "pm9GIAYQzDCE"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26612,
     "status": "ok",
     "timestamp": 1618322057094,
     "user": {
      "displayName": "Marjon Blondeel",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gg1bZUZhj06leL74e2Mn-eu1NyztKgDXIMJdj6RgQ=s64",
      "userId": "07230704137495875448"
     },
     "user_tz": -120
    },
    "id": "1XA645-hzGT7",
    "outputId": "c09846b5-608b-46c9-a118-5f6b976ad908"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Reached the goal üèÜ\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"FrozenLake-v1\", is_slippery=False, render_mode=\"human\")\n",
    "state = env.reset()[0]\n",
    "print(env.render())\n",
    "for step in range(max_steps_per_episode):\n",
    "    time.sleep(0.1)\n",
    "    clear_output(wait=True)\n",
    "    action = policy(state)       \n",
    "    state, reward, terminated, truncated, info = env.step(action)\n",
    "    env.render()  \n",
    "    done = truncated or terminated \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "if state == 15:\n",
    "    print(\"\\nReached the goal üèÜ\")\n",
    "else:\n",
    "    print(\"\\nFell into a hole ‚ò†Ô∏è\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "ah6pzMUjfzqZ"
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of 2_ReinforcementLearningIntro_solutions.ipynb",
   "provenance": [
    {
     "file_id": "1_lfz8dLcph3SxvIXFRMEShABtetZPUsU",
     "timestamp": 1640256006360
    }
   ],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
